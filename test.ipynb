{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f698d063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "import datashader as ds\n",
    "import datashader.transfer_functions as tf\n",
    "from datetime import timedelta, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from threading import Lock\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "pl.Config.set_engine_affinity(\"streaming\")\n",
    "pl.Config.set_streaming_chunk_size(200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ae35e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"SHELL\"] = \"/app/bin/host-spawn\"\n",
    "os.environ[\"PATH\"] = (\n",
    "    \"/var/home/caleb/Projects/stream-plotting/.venv/bin:/home/caleb/.local/share/zinit/plugins/starship---starship:/home/caleb/.local/share/zinit/polaris/bin:/home/linuxbrew/.linuxbrew/bin:/home/linuxbrew/.linuxbrew/sbin:/home/caleb/.cargo/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin\"\n",
    ")\n",
    "os.environ[\"POLARS_VISUALIZE_PHYSICAL_PLAN\"] = (\n",
    "    \"/home/caleb/Projects/stream-plotting/a.dot\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "994ced97",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m      4\u001b[39m lf = lf.with_columns(\n\u001b[32m      5\u001b[39m     pl.datetime_range(\n\u001b[32m      6\u001b[39m         datetime(\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     .alias(\u001b[33m\"\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m )\n\u001b[32m     17\u001b[39m lf = lf.with_columns(\n\u001b[32m     18\u001b[39m     (pl.int_range(\u001b[32m100000\u001b[39m).sample(\u001b[32m100_000_000\u001b[39m, with_replacement=\u001b[38;5;28;01mTrue\u001b[39;00m) / \u001b[32m10000\u001b[39m).alias(\n\u001b[32m     19\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m     ),\n\u001b[32m     30\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43mlf\u001b[49m\u001b[43m.\u001b[49m\u001b[43msink_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest/test\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.parquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/stream-plotting/.venv/lib/python3.12/site-packages/polars/lazyframe/frame.py:2776\u001b[39m, in \u001b[36mLazyFrame.sink_parquet\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   2774\u001b[39m     ldf = ldf.with_optimizations(optimizations._pyoptflags)\n\u001b[32m   2775\u001b[39m     ldf = LazyFrame._from_pyldf(ldf)\n\u001b[32m-> \u001b[39m\u001b[32m2776\u001b[39m     \u001b[43mldf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2777\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2778\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LazyFrame._from_pyldf(ldf)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/stream-plotting/.venv/lib/python3.12/site-packages/polars/_utils/deprecation.py:97\u001b[39m, in \u001b[36mdeprecate_streaming_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33min-memory\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mstreaming\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/stream-plotting/.venv/lib/python3.12/site-packages/polars/lazyframe/opt_flags.py:331\u001b[39m, in \u001b[36mforward_old_opt_flags.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    328\u001b[39m         optflags = cb(optflags, kwargs.pop(key))  \u001b[38;5;66;03m# type: ignore[no-untyped-call,unused-ignore]\u001b[39;00m\n\u001b[32m    330\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33moptimizations\u001b[39m\u001b[33m\"\u001b[39m] = optflags\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/stream-plotting/.venv/lib/python3.12/site-packages/polars/lazyframe/frame.py:2300\u001b[39m, in \u001b[36mLazyFrame.collect\u001b[39m\u001b[34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, engine, background, optimizations, **_kwargs)\u001b[39m\n\u001b[32m   2298\u001b[39m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[32m   2299\u001b[39m callback = _kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mpost_opt_callback\u001b[39m\u001b[33m\"\u001b[39m, callback)\n\u001b[32m-> \u001b[39m\u001b[32m2300\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "all_lf = []\n",
    "for i in range(1, 1000):\n",
    "    lf = pl.LazyFrame()\n",
    "    lf = lf.with_columns(\n",
    "        pl.datetime_range(\n",
    "            datetime(\n",
    "                2001, 1, (((i - 1) // 60) // 24) + 1, ((i - 1) // 60) % 24, (i - 1) % 60\n",
    "            ),\n",
    "            datetime(2001, 1, ((i // 60) // 24) + 1, (i // 60) % 24, i % 60),\n",
    "            \"123ns\",\n",
    "            eager=False,\n",
    "        )\n",
    "        .sample(100_000_000)\n",
    "        .sort()\n",
    "        .alias(\"time\")\n",
    "    )\n",
    "    lf = lf.with_columns(\n",
    "        (pl.int_range(100000).sample(100_000_000, with_replacement=True) / 10000).alias(\n",
    "            \"x\"\n",
    "        ),\n",
    "        (pl.int_range(100000).sample(100_000_000, with_replacement=True) / 10000).alias(\n",
    "            \"y\"\n",
    "        ),\n",
    "        (pl.int_range(10).sample(100_000_000, with_replacement=True)).alias(\n",
    "            \"group\"\n",
    "        ),\n",
    "        (pl.int_range(100000).sample(100_000_000, with_replacement=True) / 10000).alias(\n",
    "            \"colour\"\n",
    "        ),\n",
    "    )\n",
    "    lf.sink_parquet(f\"test/test{i}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baf355b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl.scan_parquet(\"test/\").head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbd1f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = pl.scan_parquet(\"test/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29dbfa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_datashader(\n",
    "    plots_dict: dict,\n",
    "    df: pl.DataFrame,\n",
    "    x: str,\n",
    "    y: str,\n",
    "    c: str,\n",
    "    period_ns: int,\n",
    "    plot_width=800,\n",
    "    plot_height=600,\n",
    "    out_dir=\".\",\n",
    "    prefix=\"plot\",\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Plots a Polars DataFrame using Datashader and returns the same DataFrame.\n",
    "    Calculates plot index using time and metadata, and uses it in the output filename.\n",
    "\n",
    "    Additional Parameters:\n",
    "    - start_time (int): Epoch timestamp in nanoseconds of the full data start.\n",
    "    - period_ns (int): Period in nanoseconds for splitting.\n",
    "    - out_dir (str): Output directory for saving plots.\n",
    "    - prefix (str): Prefix for filenames.\n",
    "    \"\"\"\n",
    "    # Determine plot index from min x (timestamp)\n",
    "    first_row = df[0]\n",
    "    group_len = first_row[\"len\"].item()\n",
    "    plot_idx = first_row[\"group_idx\"].item()\n",
    "    x_min = first_row[f\"{x}_min\"].item()\n",
    "    x_max = first_row[f\"{x}_max\"].item()\n",
    "    y_min = first_row[f\"{y}_min\"].item()\n",
    "    y_max = first_row[f\"{y}_max\"].item()\n",
    "    pdf = df.to_pandas()\n",
    "    # Create canvas and render\n",
    "    cvs = ds.Canvas(\n",
    "        plot_width=plot_width,\n",
    "        plot_height=plot_height,\n",
    "        x_range=(x_min, x_max),\n",
    "        y_range=(y_min, y_max),\n",
    "    )\n",
    "    current_agg = cvs.points(pdf, x, y, ds.mean(c))\n",
    "    lock_key = f\"{plot_idx}_lock\"\n",
    "    count_key = f\"{plot_idx}_count\"\n",
    "\n",
    "    # Initialize shared memory keys if not present\n",
    "    with plots_dict.setdefault(f\"{plot_idx}_lock\", Lock()):\n",
    "        existing = plots_dict.get(plot_idx)\n",
    "        if existing is None:\n",
    "            plots_dict[plot_idx] = current_agg.values.copy()\n",
    "            plots_dict[count_key] = np.array(df.height)\n",
    "        else:\n",
    "            np.nanmean(\n",
    "                np.dstack((existing, current_agg.values)),\n",
    "                axis=2,\n",
    "                out=plots_dict[plot_idx],\n",
    "            )\n",
    "            plots_dict[count_key] += np.array(df.height)\n",
    "\n",
    "    if plots_dict[count_key] == np.array(group_len):\n",
    "        total = np.nan_to_num(plots_dict[plot_idx], nan=0.0)\n",
    "        current_agg.values = total\n",
    "        # Save the image\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_figheight(plot_height / 100)\n",
    "        fig.set_figwidth(plot_width / 100)\n",
    "        ax.imshow(tf.shade(current_agg).to_pil(), aspect=\"auto\")\n",
    "        ax.axis(\"off\")\n",
    "        filename = f\"{out_dir}/{prefix}_{period_ns}_{plot_idx}.png\"\n",
    "        fig.savefig(filename, bbox_inches=\"tight\", pad_inches=0)\n",
    "        plt.close(fig)\n",
    "        del plots_dict[count_key]\n",
    "        del plots_dict[lock_key]\n",
    "        del plots_dict[plot_idx]\n",
    "\n",
    "\n",
    "def plot_lf(\n",
    "    lf: pl.LazyFrame, period: timedelta, x: str, y: str, c: str, out_dir=\"plots\"\n",
    "):\n",
    "    # Convert period to nanoseconds\n",
    "    # period_ns = pl.duration_string_to_duration(period).cast(pl.Int64).max().item()\n",
    "\n",
    "    # Add temporary epoch column for plotting\n",
    "    epoch_col = f\"{x}_epoch_tmp\"\n",
    "    lf = lf.set_sorted(x)\n",
    "    lf = lf.with_columns(pl.col(x).dt.epoch(\"ns\").alias(epoch_col)).with_columns(\n",
    "        (\n",
    "            (pl.col(epoch_col) - pl.col(epoch_col).min())\n",
    "            // (period.total_seconds() * 1e9)\n",
    "        )\n",
    "        .alias(\"group_idx\")\n",
    "        .cast(pl.UInt32)\n",
    "    )\n",
    "    period_ns = int(period.total_seconds() * 1e9)\n",
    "    plots = {}\n",
    "\n",
    "    def custom_plot_fn(df: pl.DataFrame):\n",
    "        for tmp_df in df.partition_by(\"group_idx\"):\n",
    "            plot_with_datashader(\n",
    "                plots,\n",
    "                tmp_df,\n",
    "                x=epoch_col,\n",
    "                y=y,\n",
    "                c=c,\n",
    "                period_ns=period_ns,\n",
    "                out_dir=out_dir,\n",
    "                prefix=\"plot\",\n",
    "            )\n",
    "        return df\n",
    "\n",
    "    # Run the dynamic grouping and plotting\n",
    "\n",
    "    agg = (\n",
    "        lf.select(epoch_col, \"group_idx\", y, c)\n",
    "        .group_by(\"group_idx\")\n",
    "        .agg(\n",
    "            pl.col(epoch_col).max().alias(f\"{epoch_col}_max\"),\n",
    "            pl.col(epoch_col).min().alias(f\"{epoch_col}_min\"),\n",
    "            pl.col(y).max().alias(f\"{y}_max\"),\n",
    "            pl.col(y).min().alias(f\"{y}_min\"),\n",
    "            pl.len().alias(\"len\"),\n",
    "        )\n",
    "    )\n",
    "    return (\n",
    "        lf.select(epoch_col, \"group_idx\", y, c)\n",
    "        .join(agg, on=\"group_idx\")\n",
    "        .map_batches(\n",
    "            custom_plot_fn,\n",
    "            predicate_pushdown=False,\n",
    "            projection_pushdown=False,\n",
    "            slice_pushdown=False,\n",
    "            streamable=True,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da7d3ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    a = plot_lf(lf.head(100000000), timedelta(seconds=1), \"time\", \"value\", \"colour\")\n",
    "    a.select(pl.col(\"value\").first()).sink_parquet(\"out.parquet\", engine=\"streaming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07a0e14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1_600, 5)\n",
      "┌───────┬───────────┬──────────┬─────┬──────────┐\n",
      "│ group ┆ time      ┆ x        ┆ y   ┆ colour   │\n",
      "│ ---   ┆ ---       ┆ ---      ┆ --- ┆ ---      │\n",
      "│ i64   ┆ f64       ┆ f64      ┆ f64 ┆ f64      │\n",
      "╞═══════╪═══════════╪══════════╪═════╪══════════╡\n",
      "│ 1     ┆ 0.0       ┆ 0.0      ┆ 0.5 ┆ 0.280678 │\n",
      "│ 1     ┆ 0.10101   ┆ 0.010101 ┆ 0.5 ┆ 0.901677 │\n",
      "│ 1     ┆ 0.20202   ┆ 0.020202 ┆ 0.5 ┆ 0.282514 │\n",
      "│ 1     ┆ 0.30303   ┆ 0.030303 ┆ 0.5 ┆ 0.55766  │\n",
      "│ 1     ┆ 0.40404   ┆ 0.040404 ┆ 0.5 ┆ 0.733112 │\n",
      "│ …     ┆ …         ┆ …        ┆ …   ┆ …        │\n",
      "│ 1     ┆ 159.59596 ┆ 0.959596 ┆ 0.5 ┆ 0.4623   │\n",
      "│ 1     ┆ 159.69697 ┆ 0.969697 ┆ 0.5 ┆ 0.653025 │\n",
      "│ 1     ┆ 159.79798 ┆ 0.979798 ┆ 0.5 ┆ 0.458468 │\n",
      "│ 1     ┆ 159.89899 ┆ 0.989899 ┆ 0.5 ┆ 0.683186 │\n",
      "│ 1     ┆ 160.0     ┆ 1.0      ┆ 0.5 ┆ 0.075853 │\n",
      "└───────┴───────────┴──────────┴─────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "groups = [1]  # single group for testing\n",
    "grid_x, grid_y = 4, 4\n",
    "interval = 10  # seconds per tile\n",
    "n_tiles = grid_x * grid_y\n",
    "\n",
    "n_points_per_shape = 100\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for group in groups:\n",
    "    for tile_idx in range(n_tiles):\n",
    "        time_base = tile_idx * interval\n",
    "\n",
    "        # Choose a shape type based on tile index for variety\n",
    "        shape_type = tile_idx % 3  # 0=line, 1=diagonal, 2=circle\n",
    "\n",
    "        if shape_type == 0:\n",
    "            # Horizontal line at y=0.5\n",
    "            x = np.linspace(0,1,n_points_per_shape)\n",
    "            y = np.full_like(x, 0.5)\n",
    "        elif shape_type == 1:\n",
    "            # Diagonal line y=x\n",
    "            x = np.linspace(0,1,n_points_per_shape)\n",
    "            y = x.copy()\n",
    "        else:\n",
    "            # Circle centered at (0.5,0.5) radius 0.4\n",
    "            theta = np.linspace(0, 2*np.pi, n_points_per_shape)\n",
    "            x = 0.5 + 0.4 * np.cos(theta)\n",
    "            y = 0.5 + 0.4 * np.sin(theta)\n",
    "\n",
    "        # Create time values within this interval\n",
    "        times = np.linspace(time_base, time_base + interval, n_points_per_shape)\n",
    "\n",
    "        # Random colour values between 0 and 1 for demonstration\n",
    "        colours = np.random.rand(n_points_per_shape)\n",
    "\n",
    "        df_tile = pl.DataFrame({\n",
    "            'group': np.full(n_points_per_shape, group),\n",
    "            'time': times,\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'colour': colours\n",
    "        })\n",
    "\n",
    "        all_data.append(df_tile)\n",
    "\n",
    "# Combine all tiles into a single dataframe\n",
    "df_test = pl.concat(all_data)\n",
    "\n",
    "print(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275bb967",
   "metadata": {},
   "outputs": [],
   "source": [
    "4*10*10\n",
    "30*4*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f233b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import datashader as ds\n",
    "import datashader.transfer_functions as tf\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "torch.set_num_threads(1)\n",
    "# Parameters\n",
    "tile_w, tile_h = 256, 256\n",
    "grid_x, grid_y = 5, 5\n",
    "interval = 100000000  # seconds per tile\n",
    "batch_interval = interval * grid_x * grid_y\n",
    "\n",
    "composite_w = tile_w * grid_x\n",
    "composite_h = tile_h * grid_y\n",
    "\n",
    "output_folder = \"plots\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "# Create Datashader canvas covering the full composite size\n",
    "cvs = ds.Canvas(plot_width=composite_w, plot_height=composite_h)\n",
    "def render_composite(df):\n",
    "    grp = df['group'][0]\n",
    "    batch_time = df['batch_time_window'][0]\n",
    "    # Convert to pandas for Datashader processing\n",
    "    df_pd = df['x_canvas', 'y_canvas','colour'].to_pandas(use_threads=False, split_blocks=True)\n",
    "\n",
    "    # Render points onto composite\n",
    "    agg = cvs.points(df_pd, 'x_canvas', 'y_canvas', ds.mean('colour'))\n",
    "    img = tf.set_background(tf.shade(agg), \"white\").to_pil()\n",
    "    # Convert to tensor: [H, W, C] -> [C, H, W]\n",
    "    tensor = torch.from_numpy(np.array(img)).permute(2,0,1).float().div(255)\n",
    "    # tensor_tiles: [n_tiles, C, tile_h, tile_w]\n",
    "    tensor_tiles = tensor.view(\n",
    "        4,\n",
    "        grid_y, tile_h,\n",
    "        grid_x, tile_w\n",
    "    ).permute(1,3,0,2,4).reshape(-1, 4, tile_h, tile_w)\n",
    "\n",
    "    # Save tensor batch\n",
    "    \n",
    "    torch.save(tensor_tiles, f\"{output_folder}/{grp}_{batch_time}.pt\")\n",
    "\n",
    "    # Return original DataFrame to Polars\n",
    "    return pl.DataFrame({\"tmp\": [1]})\n",
    "\n",
    "# Example Polars pipeline\n",
    "df = lf.head(50_000_000)\n",
    "# Assume df is your lazy Polars dataframe with 'group', 'time', 'x', 'y', 'colour'\n",
    "# df = pl.scan_parquet(\"\")\n",
    "# Compute tile indices and shifted canvas coordinates\n",
    "df = df.with_columns([\n",
    "    ((pl.col('time').dt.epoch(\"ns\") // interval).alias('time_window')),\n",
    "])\n",
    "\n",
    "# Compute batch time window index (covers entire composite)\n",
    "df = df.with_columns([\n",
    "    ((pl.col('time_window') // (grid_x * grid_y)) * (grid_x * grid_y)).alias('batch_time_window')\n",
    "])\n",
    "\n",
    "# Compute tile row and column within grid\n",
    "df = df.with_columns([\n",
    "    ((pl.col('time_window') % (grid_x * grid_y)) // grid_x).alias('tile_row'),\n",
    "    ((pl.col('time_window') % (grid_x * grid_y)) % grid_x).alias('tile_col'),\n",
    "])\n",
    "\n",
    "# Compute per-tile x and y (normalize if needed to [0,1])\n",
    "# Here assuming x,y are normalized already:\n",
    "df = df.with_columns(\n",
    "    (pl.col('x') - pl.col('x').min()) / pl.col('x').max(),\n",
    "    (pl.col('y') - pl.col('y').min()) / pl.col('y').max()\n",
    ")\n",
    "df = df.with_columns([\n",
    "    (pl.col('x') * tile_w + pl.col('tile_col') * tile_w).alias('x_canvas'),\n",
    "    (pl.col('y') * tile_h + pl.col('tile_row') * tile_h).alias('y_canvas'),\n",
    "])\n",
    "result = df.select([\n",
    "    \"group\",\n",
    "    \"batch_time_window\",\n",
    "    pl.col('x_canvas').cast(pl.Float32),\n",
    "    pl.col('y_canvas').cast(pl.Float32),\n",
    "    pl.col('colour').cast(pl.Float32)\n",
    "]).group_by(['group', 'batch_time_window']).map_groups(render_composite, schema=pl.Schema({\"tmp\":pl.Int64}))\n",
    "# # Group by group and batch_time_window to process each composite canvas\n",
    "# result = df.select('group', 'batch_time_window', 'x_canvas', 'y_canvas','colour').group_by(['group', 'batch_time_window']).map_groups(render_composite, schema=pl.Schema({\"tmp\":pl.Int64}))\n",
    "\n",
    "\n",
    "# # # Trigger execution (side effects will run here)\n",
    "_ = result.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8cfcace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.load(output_folder+\"/6_9783072175.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bf299ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 4, 256, 256])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49db03cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "transform = T.ToPILImage()\n",
    "for x in range(10):\n",
    "    img = transform(tensor[x])\n",
    "    img.save(f'{x}.png', format='PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed45e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = lf.head(100000000)\n",
    "a = (\n",
    "    plot_lf(lf, timedelta(seconds=30), \"time\", \"value\", \"colour\")\n",
    "    .select(pl.col(\"value\").first())\n",
    "    .sink_parquet(\"out.tmp\", engine=\"streaming\", lazy=True)\n",
    ")\n",
    "b = (\n",
    "    plot_lf(lf, timedelta(seconds=10), \"time\", \"value\", \"colour\")\n",
    "    .select(pl.col(\"value\").first())\n",
    "    .sink_parquet(\"out.tmp\", engine=\"streaming\", lazy=True)\n",
    ")\n",
    "c = (\n",
    "    plot_lf(lf, timedelta(seconds=2), \"time\", \"value\", \"colour\")\n",
    "    .select(pl.col(\"value\").first())\n",
    "    .sink_parquet(\"out.tmp\", engine=\"streaming\", lazy=True)\n",
    ")\n",
    "d = (\n",
    "    plot_lf(lf, timedelta(milliseconds=1000), \"time\", \"value\", \"colour\")\n",
    "    .select(pl.col(\"value\").first())\n",
    "    .sink_parquet(\"out.tmp\", engine=\"streaming\", lazy=True)\n",
    ")\n",
    "pl.collect_all([a, b, c, d], engine=\"streaming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62efa2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pl.explain_all([a, b, c, d]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "374857d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "odf = df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a4af7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         3709 function calls (3600 primitive calls) in 0.385 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 575 to 20 due to restriction <20>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.288    0.288 /home/caleb/Projects/stream-plotting/.venv/lib/python3.12/site-packages/datashader/core.py:183(points)\n",
      "        1    0.000    0.000    0.287    0.287 /home/caleb/Projects/stream-plotting/.venv/lib/python3.12/site-packages/datashader/core.py:1326(bypixel)\n",
      "      2/1    0.000    0.000    0.287    0.287 /home/caleb/Projects/stream-plotting/.venv/lib/python3.12/site-packages/datashader/utils.py:111(__call__)\n",
      "        1    0.000    0.000    0.287    0.287 /home/caleb/Projects/stream-plotting/.venv/lib/python3.12/site-packages/datashader/data_libraries/pandas.py:15(pandas_pipeline)\n",
      "        1    0.000    0.000    0.287    0.287 /home/caleb/Projects/stream-plotting/.venv/lib/python3.12/site-packages/datashader/data_libraries/pandas.py:23(default)\n",
      "        1    0.233    0.233    0.233    0.233 /home/caleb/Projects/stream-plotting/.venv/lib/python3.12/site-packages/datashader/glyphs/points.py:223(extend)\n",
      "        2    0.049    0.025    0.049    0.025 /home/caleb/Projects/stream-plotting/.venv/lib/python3.12/site-packages/datashader/glyphs/glyph.py:51(_compute_bounds)\n",
      "        1    0.000    0.000    0.043    0.043 /home/caleb/Projects/stream-plotting/.venv/lib/python3.12/site-packages/polars/dataframe/frame.py:2362(to_pandas)\n",
      "        1    0.000    0.000    0.043    0.043 /home/caleb/Projects/stream-plotting/.venv/lib/python3.12/site-packages/polars/dataframe/frame.py:2497(_to_pandas_without_object_columns)\n",
      "        1    0.043    0.043    0.043    0.043 {method 'to_pandas' of 'builtins.PyDataFrame' objects}\n",
      "        1    0.000    0.000    0.036    0.036 /home/caleb/Projects/stream-plotting/.venv/lib/python3.12/site-packages/IPython/core/history.py:1024(writeout_cache)\n",
      "        1    0.000    0.000    0.035    0.035 /home/caleb/Projects/stream-plotting/.venv/lib/python3.12/site-packages/IPython/core/history.py:1008(_writeout_input_cache)\n",
      "        2    0.035    0.018    0.035    0.018 {method '__exit__' of 'sqlite3.Connection' objects}\n",
      "        1    0.000    0.000    0.027    0.027 /home/caleb/Projects/stream-plotting/.venv/lib/python3.12/site-packages/datashader/glyphs/points.py:145(compute_x_bounds)\n",
      "        1    0.000    0.000    0.022    0.022 /home/caleb/Projects/stream-plotting/.venv/lib/python3.12/site-packages/datashader/glyphs/points.py:149(compute_y_bounds)\n",
      "        1    0.014    0.014    0.014    0.014 {method 'max' of 'torch._C.TensorBase' objects}\n",
      "        1    0.002    0.002    0.003    0.003 /home/caleb/Projects/stream-plotting/.venv/lib/python3.12/site-packages/datashader/reductions.py:1292(_finalize)\n",
      "        1    0.000    0.000    0.002    0.002 /home/caleb/Projects/stream-plotting/.venv/lib/python3.12/site-packages/torch/serialization.py:822(_open_zipfile_writer)\n",
      "        1    0.001    0.001    0.002    0.002 /home/caleb/Projects/stream-plotting/.venv/lib/python3.12/site-packages/torch/serialization.py:775(__init__)\n",
      "        1    0.000    0.000    0.001    0.001 /home/caleb/Projects/stream-plotting/.venv/lib/python3.12/site-packages/xarray/core/dataarray.py:432(__init__)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "import io\n",
    "\n",
    "# Import your modules and define variables (replace ... as appropriate)\n",
    "import torch\n",
    "import polars as pl\n",
    "import datashader as ds\n",
    "import datashader.transfer_functions as tf\n",
    "import numpy as np\n",
    "\n",
    "# Define your function here (copy of render_composite)\n",
    "def render_composite(df):\n",
    "    grp = df['group'][0]\n",
    "    batch_time = df['batch_time_window'][0]\n",
    "    df_pd = df['x_canvas', 'y_canvas','colour'].to_pandas(use_threads=False, split_blocks=True)\n",
    "    agg = cvs.points(df_pd, 'x_canvas', 'y_canvas', ds.mean('colour'))\n",
    "    # img = tf.shade(agg)\n",
    "    # img = tf.set_background(img, \"white\")\n",
    "    # img = img.to_pil()\n",
    "    arr = agg.values\n",
    "\n",
    "    # # Normalize counts to 0-255 grayscale\n",
    "    # arr_norm = 255 - (arr / arr.max() * 255)\n",
    "\n",
    "    # # Fill NaNs with 255 (white background)\n",
    "    # # arr_norm = np.nan_to_num(arr_norm, nan=255)\n",
    "    # tensor = torch.from_numpy(arr_norm).unsqueeze(0).permute(2,0,1).float().div(255)\n",
    "    # tensor_tiles = tensor.view(\n",
    "    #     1,\n",
    "    #     grid_y, tile_h,\n",
    "    #     grid_x, tile_w\n",
    "    # ).permute(1,3,0,2,4).reshape(-1, 1, tile_h, tile_w)\n",
    "    tensor = torch.from_numpy(arr).float()  # shape [H, W]\n",
    "\n",
    "    # Reshape to tiles\n",
    "    tensor_tiles = tensor.view(\n",
    "        grid_y, tile_h,\n",
    "        grid_x, tile_w\n",
    "    ).permute(0,2,1,3).reshape(-1, tile_h, tile_w)  # shape [num_tiles, tile_h, tile_w]\n",
    "\n",
    "    # Per-tile normalisation\n",
    "    tile_max = tensor_tiles.view(tensor_tiles.size(0), -1).max(dim=1)[0]  # shape [num_tiles]\n",
    "\n",
    "    # Avoid division by zero\n",
    "    tile_max[tile_max == 0] = 1.0\n",
    "\n",
    "    # Normalise each tile by its own max\n",
    "    tensor_tiles = tensor_tiles / tile_max[:, None, None]\n",
    "\n",
    "    # Invert to match white background, black data convention\n",
    "    tensor_tiles = 1.0 - tensor_tiles\n",
    "\n",
    "    # Scale to [0,255] and cast to uint8 if needed\n",
    "    tensor_tiles = (tensor_tiles * 255).clamp(0,255).byte()\n",
    "\n",
    "    # Add channel dimension\n",
    "    tensor_tiles = tensor_tiles.unsqueeze(1)\n",
    "    torch.save(tensor_tiles, f\"{output_folder}/{grp}_{batch_time}.pt\")\n",
    "    return pl.DataFrame({\"tmp\": [1]})\n",
    "\n",
    "# Example: Prepare a dummy dataframe for testing (replace with real data)\n",
    "df = odf\n",
    "\n",
    "# Set up any needed globals the function expects\n",
    "tile_w, tile_h, grid_x, grid_y = 256, 256, 5, 5\n",
    "composite_w = tile_w * grid_x\n",
    "composite_h = tile_h * grid_y\n",
    "output_folder = \"plots\"\n",
    "cvs = ds.Canvas(plot_width=composite_w, plot_height=composite_h)\n",
    "\n",
    "# --- Profiling section ---\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "\n",
    "render_composite(df)\n",
    "\n",
    "pr.disable()\n",
    "s = io.StringIO()\n",
    "ps = pstats.Stats(pr, stream=s).sort_stats('cumtime')\n",
    "ps.print_stats(20)  # show top 20 functions by cumulative time\n",
    "print(s.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9abe7e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 0.0106277 s\n",
      "File: /tmp/ipykernel_44539/595703613.py\n",
      "Function: render_composite at line 13\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    13                                           def render_composite(df):\n",
      "    14         1      22090.0  22090.0      0.2      grp = df['group'][0]\n",
      "    15         1       4060.0   4060.0      0.0      batch_time = df['batch_time_window'][0]\n",
      "    16         1     912704.0 912704.0      8.6      df_pd = df['x_canvas', 'y_canvas','colour'].to_pandas(use_threads=False, split_blocks=True)\n",
      "    17         1    4365789.0    4e+06     41.1      agg = cvs.points(df_pd, 'x_canvas', 'y_canvas', ds.mean('colour'))\n",
      "    18                                               # img = tf.shade(agg)\n",
      "    19                                               # img = tf.set_background(img, \"white\")\n",
      "    20                                               # img = img.to_pil()\n",
      "    21         1      12210.0  12210.0      0.1      arr = agg.values\n",
      "    22                                           \n",
      "    23                                               # # Normalize counts to 0-255 grayscale\n",
      "    24                                               # arr_norm = 255 - (arr / arr.max() * 255)\n",
      "    25                                           \n",
      "    26                                               # # Fill NaNs with 255 (white background)\n",
      "    27                                               # # arr_norm = np.nan_to_num(arr_norm, nan=255)\n",
      "    28                                               # tensor = torch.from_numpy(arr_norm).unsqueeze(0).permute(2,0,1).float().div(255)\n",
      "    29                                               # tensor_tiles = tensor.view(\n",
      "    30                                               #     1,\n",
      "    31                                               #     grid_y, tile_h,\n",
      "    32                                               #     grid_x, tile_w\n",
      "    33                                               # ).permute(1,3,0,2,4).reshape(-1, 1, tile_h, tile_w)\n",
      "    34         1     763995.0 763995.0      7.2      tensor = torch.from_numpy(arr).float()  # shape [H, W]\n",
      "    35                                           \n",
      "    36                                               # Reshape to tiles\n",
      "    37         3      19630.0   6543.3      0.2      tensor_tiles = tensor.view(\n",
      "    38         1        720.0    720.0      0.0          grid_y, tile_h,\n",
      "    39         1        280.0    280.0      0.0          grid_x, tile_w\n",
      "    40         1     462256.0 462256.0      4.3      ).permute(0,2,1,3).reshape(-1, tile_h, tile_w)  # shape [num_tiles, tile_h, tile_w]\n",
      "    41                                           \n",
      "    42                                               # Per-tile normalisation\n",
      "    43         1      34460.0  34460.0      0.3      tile_max = tensor_tiles.view(tensor_tiles.size(0), -1).max(dim=1)[0]  # shape [num_tiles]\n",
      "    44                                           \n",
      "    45                                               # Avoid division by zero\n",
      "    46         1      44540.0  44540.0      0.4      tile_max[tile_max == 0] = 1.0\n",
      "    47                                           \n",
      "    48                                               # Normalise each tile by its own max\n",
      "    49         1     317848.0 317848.0      3.0      tensor_tiles = tensor_tiles / tile_max[:, None, None]\n",
      "    50                                           \n",
      "    51                                               # Invert to match white background, black data convention\n",
      "    52         1     234218.0 234218.0      2.2      tensor_tiles = 1.0 - tensor_tiles\n",
      "    53                                           \n",
      "    54                                               # Scale to [0,255] and cast to uint8 if needed\n",
      "    55         1     996833.0 996833.0      9.4      tensor_tiles = (tensor_tiles * 255).clamp(0,255).byte()\n",
      "    56                                           \n",
      "    57                                               # Add channel dimension\n",
      "    58         1       7310.0   7310.0      0.1      tensor_tiles = tensor_tiles.unsqueeze(1)\n",
      "    59         1    2202034.0    2e+06     20.7      torch.save(tensor_tiles, f\"{output_folder}/{grp}_{batch_time}.pt\")\n",
      "    60         1     226698.0 226698.0      2.1      return pl.DataFrame({\"tmp\": [1]})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from line_profiler import LineProfiler\n",
    "\n",
    "lp = LineProfiler()\n",
    "lp.add_function(render_composite)\n",
    "lp_wrapper = lp(render_composite)\n",
    "lp_wrapper(df.head(100))\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d334cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = canvas.points(df, 'x', 'y')\n",
    "\n",
    "# Convert to numpy array\n",
    "arr = agg.values\n",
    "\n",
    "# Normalize counts to 0-255 grayscale\n",
    "arr_norm = arr / arr.max() * 255\n",
    "arr_norm = 255 - arr_norm  # invert to match white bg, black points\n",
    "\n",
    "# Fill NaNs with 255 (white background)\n",
    "arr_norm = np.nan_to_num(arr_norm, nan=255)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
